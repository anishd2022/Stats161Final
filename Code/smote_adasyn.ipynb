{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552705b6-e304-4313-ad53-32d84e2ca849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, accuracy_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "_splitter = re.compile(r\"[,;\\^\\s]+\")\n",
    "\n",
    "def count_listish(x):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return 0\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s == \"[]\":\n",
    "        return 0\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        s = s[1:-1]\n",
    "    parts = [p for p in _splitter.split(s) if p]\n",
    "    return len(parts)\n",
    "\n",
    "def eval_at_threshold(y_true, y_prob, thr=0.5, label=\"Model\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    pr_auc = average_precision_score(y_true, y_prob)\n",
    "    print(f\"\\n{label} @ threshold={thr:.3f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, \"\n",
    "          f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}\")\n",
    "    return {\n",
    "        \"thr\": thr, \"precision\": precision, \"recall\": recall, \"accuracy\": acc,\n",
    "        \"f1\": f1, \"roc_auc\": roc_auc, \"pr_auc\": pr_auc\n",
    "    }\n",
    "\n",
    "def best_threshold_by_f1(y_true, y_prob, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.02, 0.50, 49)\n",
    "    best = (-1, 0.5)\n",
    "    for t in grid:\n",
    "        f1 = f1_score(y_true, (y_prob >= t).astype(int), zero_division=0)\n",
    "        if f1 > best[0]:\n",
    "            best = (f1, t)\n",
    "    return best[1]\n",
    "\n",
    "# loading data\n",
    "ads_train = pd.read_csv(\"train_data_ads.csv\")\n",
    "ads_test = pd.read_csv(\"test_data_ads.csv\")\n",
    "feeds_train = pd.read_csv(\"train_data_feeds.csv\")\n",
    "feeds_test = pd.read_csv(\"test_data_feeds.csv\")\n",
    "print(\"Data loaded\")\n",
    "\n",
    "# preprocessing ads data\n",
    "def preprocess_ads(df):\n",
    "    categorical_cols_ads = [\n",
    "        'age', 'gender', 'residence', 'city', 'city_rank', 'series_dev', 'series_group',\n",
    "        'emui_dev', 'device_name', 'device_size', 'net_type', 'task_id', 'adv_id',\n",
    "        'creat_type_cd', 'adv_prim_id', 'inter_type_cd', 'slot_id', 'site_id',\n",
    "        'spread_app_id', 'hispace_app_tags', 'app_second_class'\n",
    "    ]\n",
    "    df = df.copy()\n",
    "    for col in categorical_cols_ads:\n",
    "        if col in df.columns:\n",
    "            # Convert to numeric to preserve original categorical values (not shifted to 0)\n",
    "            # Fill missing values with -1 as a sentinel value\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    list_cols_click = ['ad_click_list_001', 'ad_click_list_002', 'ad_click_list_003']\n",
    "    list_cols_close = ['ad_close_list_001', 'ad_close_list_002', 'ad_close_list_003']\n",
    "    for col in list_cols_click:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('[]').apply(count_listish)\n",
    "    for col in list_cols_close:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('[]').apply(count_listish)\n",
    "\n",
    "    if 'pt_d' in df.columns:\n",
    "        s = pd.to_datetime(df['pt_d'].astype(str), format='%Y%m%d%H%M', errors='coerce')\n",
    "        if s.isna().all():\n",
    "            s = pd.to_datetime(df['pt_d'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "        df['hour'] = s.dt.hour.fillna(-1).astype(int)\n",
    "        df['dayofweek'] = s.dt.dayofweek.fillna(-1).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# preprocessing feeds data\n",
    "def preprocess_feeds(df):\n",
    "    categorical_cols_feeds = [\n",
    "        'u_phonePrice', 'u_browserLifeCycle', 'u_browserMode', 'u_feedLifeCycle',\n",
    "        'u_newsCatInterests', 'u_newsCatDislike', 'u_newsCatInterestsST',\n",
    "        'i_s_sourceId','i_regionEntity','i_cat','I_dtype',\n",
    "        'e_ch','e_m','e_pl','e_section'\n",
    "    ]\n",
    "    list_cols_feeds = ['u_newsCatInterests','u_newsCatDislike','u_newsCatInterestsST',\n",
    "                       'u_click_ca2_news','i_entities']\n",
    "\n",
    "    df = df.copy()\n",
    "    for col in list_cols_feeds:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('[]').apply(count_listish)\n",
    "\n",
    "    for col in categorical_cols_feeds:\n",
    "        if col in df.columns:\n",
    "            # Convert to numeric to preserve original categorical values (not shifted to 0)\n",
    "            # Fill missing values with -1 as a sentinel value\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    # extract time\n",
    "    if 'e_et' in df.columns:\n",
    "        s = pd.to_datetime(df['e_et'].astype(str), format='%Y%m%d%H%M', errors='coerce')\n",
    "        if s.isna().all():\n",
    "            s = pd.to_datetime(df['e_et'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "        df['e_hour'] = s.dt.hour.fillna(-1).astype(int)\n",
    "        df['e_dayofweek'] = s.dt.dayofweek.fillna(-1).astype(int)\n",
    "\n",
    "    if 'label' in df.columns:\n",
    "        df['label'] = df['label'].map({1:1, -1:0})\n",
    "\n",
    "    return df\n",
    "\n",
    "def aggregate_feeds_user(df):\n",
    "    agg_cols = [\n",
    "        'u_phonePrice','u_browserLifeCycle','u_browserMode','u_feedLifeCycle',\n",
    "        'u_refreshTimes','u_newsCatInterests','u_newsCatDislike',\n",
    "        'u_newsCatInterestsST','u_click_ca2_news'\n",
    "    ]\n",
    "    agg_dict = {col: 'mean' for col in agg_cols if col in df.columns}\n",
    "    if 'label' in df.columns:\n",
    "        agg_dict['label'] = 'mean'\n",
    "    agg = df.groupby('u_userId').agg(agg_dict).reset_index()\n",
    "    agg.columns = ['u_userId'] + [f'feeds_{c}' for c in agg.columns if c != 'u_userId']\n",
    "    return agg\n",
    "\n",
    "train_ads_p = preprocess_ads(ads_train)\n",
    "test_ads_p  = preprocess_ads(ads_test)\n",
    "train_feeds_p = preprocess_feeds(feeds_train)\n",
    "test_feeds_p  = preprocess_feeds(feeds_test)\n",
    "print(\"Data preprocessed\")\n",
    "\n",
    "all_feeds = pd.concat([train_feeds_p, test_feeds_p], axis=0, ignore_index=True)\n",
    "feeds_user_agg = aggregate_feeds_user(all_feeds)\n",
    "\n",
    "train_merged = train_ads_p.merge(feeds_user_agg, left_on='user_id', right_on='u_userId', how='left').fillna(0)\n",
    "test_merged  = test_ads_p.merge(feeds_user_agg,  left_on='user_id', right_on='u_userId',  how='left').fillna(0)\n",
    "train_merged = train_merged.drop(columns=['u_userId'], errors='ignore')\n",
    "test_merged  = test_merged.drop(columns=['u_userId'], errors='ignore')\n",
    "print(\"Data merged\")\n",
    "\n",
    "target = 'label'\n",
    "X = train_merged.drop(columns=[target], errors='ignore')\n",
    "y = train_merged[target] if target in train_merged.columns else None\n",
    "print(\"Data prepared\")\n",
    "\n",
    "for col in ['pt_d', 'log_id']:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(columns=[col])\n",
    "    if col in test_merged.columns:\n",
    "        test_merged = test_merged.drop(columns=[col])\n",
    "\n",
    "for df_ in [X, test_merged]:\n",
    "    obj_cols = df_.select_dtypes(include=['object']).columns\n",
    "    if len(obj_cols):\n",
    "        df_.drop(columns=obj_cols, inplace=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Data split\")\n",
    "\n",
    "# Generate SMOTE + ADASYN\n",
    "class_counts = np.bincount(y_train)\n",
    "print(\"Original training class counts:\", class_counts)\n",
    "\n",
    "neg, pos = class_counts[0], class_counts[1]\n",
    "scale_pos_weight_val = neg / pos\n",
    "print(\"Recommended scale_pos_weight:\", scale_pos_weight_val)\n",
    "\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=\"auto\",   \n",
    "    random_state=42,\n",
    "    k_neighbors=5\n",
    ")\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE class counts:\", np.bincount(y_train_sm))\n",
    "\n",
    "smote_df = pd.DataFrame(X_train_sm, columns=X_train.columns)\n",
    "smote_df[\"label\"] = y_train_sm.values\n",
    "smote_df.to_csv(\"synthetic_train_SMOTE_raw.csv\", index=False)\n",
    "print(\"SMOTE data saved to csv\")\n",
    "\n",
    "# ADASYN\n",
    "adasyn = ADASYN(\n",
    "    sampling_strategy=\"auto\", \n",
    "    random_state=42,\n",
    "    n_neighbors=5\n",
    ")\n",
    "X_train_ada, y_train_ada = adasyn.fit_resample(X_train, y_train)\n",
    "print(\"After ADASYN class counts:\", np.bincount(y_train_ada))\n",
    "\n",
    "adasyn_df = pd.DataFrame(X_train_ada, columns=X_train.columns)\n",
    "adasyn_df[\"label\"] = y_train_ada.values\n",
    "adasyn_df.to_csv(\"synthetic_train_ADASYN_raw.csv\", index=False)\n",
    "print(\"ADASYN data saved to csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
